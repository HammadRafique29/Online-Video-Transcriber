 Hello everyone, welcome to the video how to automate post API tests with Postman. Let's begin. In this video I want to show you how to do a happy path test case for crude operations. Create, read, update and delete. And the corresponding method for those post, get, put and delete. And we are going to start from the post endpoint. As a usual, we will start from the user story. A bad user story. We don't have acceptance criteria, descriptions or any explanation at all. We have a list of the endpoint. And the Spagger link. Let's check it. A Spagger is a tool for API documentation. We should be able to find here all the information needed for at least a happy path test case. And we are going to test endpoints specified in the user story. Post, put, get and delete. It is logical to start from the post endpoint. As we need to know how to create data. When we expand the endpoint, we can see more documentation. The sample of the request body. That method is post and URL details. But in general, this information provides more questions than answers. We don't know if all parameters are acquired or if some of those are optional. We don't know if any of these fields have any backend logic. We don't know if we need to set some data as preconditions. So what do we do now? We know that we are the experts. And when the experts need to test something like this, the expert starts with manual exposure testing. Yes, manual. You can't automate if you can't write a manual test case. But don't worry, in this video, we'll skip a lot. So let's keep the exploratory testing and go to its results. We drank a lot of coffee and played a lot of food ball. We did a little bit of testing. As a result, we managed to send a valid request. You can see the data in the C URL. The valid ID, valid name and other parameters. And we are able to receive a valid response. You can see the data is in the response. The cat, Tom, is there in the response and all the data related to it. The spagger is a good tool, but we prefer postman. Let's copy the request data, the C URL, and paste it into the postman. And again, we are going to skip how we copy-paste the data. All that you need to know, we used in the import feature. So we used the import feature and were able to send the request and receive the response successfully. Let's save the data to the postman. And as usual, we will skip the steps. I have created another folder in our pet store collection called it crude and saved the post request here. What's next? To be able to automate the tests, we need to have the tests themselves. So let's write a couple of them. And we have a very simple checklist. The response code should be 200 OK. The response body structure is valid. And the response body data should be valid. Let's test these checks manually first. The first test gate is simple. We can see the response code is 200. If I was the easiest one, let's move to the second one. The response body structure is valid. We don't have the proper documentation. How can we test it? In this kind of situation, I recommend assuming that what you receive is what you expect. And then clarify with the responsible person. For now, we will assume that what is received in the response we see is valid data. It will be our expect result. And when we talk about the structure, it means Carly brackets, square brackets, arrays and elements. And the purpose of this is to catch the moment when the response body structure is changed. It can lead to different consequences for UI or integrated services. How can we test this manually? First of all, we need to save the current response. From today, it will be our expected result. The rule is simple. If we don't change what we sent in the request, then nothing should change in the response. Now, when it is saved, we can use it tomorrow in a week or in a month to check what we got previously and compare it. But how could we compare it? Manually, it is not an easy task. So we'll need a tool. And you know, I like very expensive tools like Google Sheets or Paint. This one is the nodepad. But advanced version nodepad plus plus. We need to paste the experiment result here. Now we need to send the request one more time. Just to change some values this time. This time, we will send ID2. And we won't send one of the elements, the photos array. And we can see that the response body is different. And we see different data. Let's compare it anyway. Carly the response body. And when we paste it into the nodepad plus plus, we used to compare feature. So we have the expected result is on the left. And the actual result is on the right. We can see that the IDs are not the same. But it is not what we are interested in. We are interested in the response body structure. And we can see the difference in the photo URL element. Of course, it is a simulation of the bug. But if the response body will be different, you will be able to catch it in this way. This is my way. Let me know if you have a more sufficient way in the comments or questions. So we tested two test cases. The response code is 200 OK. And the response body structure. The last one is about the valid data. And in this test case, we're going to check if the data will send in the request is the same as the data we received in the response. As you see, we sent ID1 and received ID1. We sent the name Tom and received the name Tom. And we need to check the entire response body like this. How can we check this? It is the same as we did in the previous test case. We copy base everything to the nodepad plus plus and compare. And we can see that everything is the same. Let's break it. This API has backend logic. If you send 0 as the ID, then you receive a huge number as the ID instead of the 0. Let's compare request and response one more time. And the size of the data doesn't match. We didn't know if it is valid behavior or a bug. But this will help you to get an automation. I just wanted to show you that even when we have only three test cases, testing the API manually is not an easy task. It is possible and we can continue to just manually. But to automate it, less simple stuff will help a lot. We have a very simple API. And to check these three task cases manually can take like a couple of minutes. But there are API monsters out there. The response can contain 100 plus fields. The API can be with complex logic and you need 100 plus test cases to test it. And this will make manual testing possible but struggling. And with Postman automation is easy. As I said, I'm the manual QA. I'm not an automation engineer. And this is the course for manual QAs. If you know programming language, great. If you don't know, even better. Just don't be intimidated by this video. This video is an introduction, not a tutorial. We will learn everything step by step in the following. Now I want to show you what kind of magic you'll be able to do after completing the course. This is the first step. It's not a tutorial. It's not a tutorial. It's not a tutorial. Without further ado, let's automate these three test cases. The first test case is the simple one. You just check if the response code is 200 okay. It is so simple that you may wonder why we need to automate it at all. You will see it in the future why. But the main reason it is very simple to automate. All we need to do is to go to the test step, here on the screen. And on the top you can see the snippets. One of them says code is 200. Click on it. That's all. Congratulations. You have originally your first test in the postman. I told you it will be easy. And now if you will send a request, valid request. You can see here that one test is run and it is successful because it is green. That's all. That's how postman automation works. It is cool, isn't it? Next, it is a very simple test, but it is a good idea to check if it works properly. So we need to force it to fail. We are the testers, aren't we? We know what to do and how to break things. In my case, I changed the ID value to the character. It led to the response code 500, the server error. And as you can see, the test is failed because it is red. So now we are sure everything is okay. The test case works. Let's fix our data. We are done with the response code. Let's move to the interesting stuff. The second test case, check the body structure. It will be the interesting one. So we need to check if the response body structure is the same. All these brackets, key value pairs and arrays from where to start. From the same place, we started the manual testing. We need the expected result. We have spun their request and we receive the response. This response, which we received today, will become our expected result. And in the future, we will compare our responses to the swan. So what we need to do to save it, but in a different manner. We need to go to the pre-request script tab in the postman. And there we need to find another snippet. Send a global variable. Click on it. It will create another script. It is not the test. This test case is not as easy as the first one with a response of 200 OK. The script will include two things, with variable key and variable value. And we need to set our data there. And again, I will skip a lot of work I have done. I set the name of the variable, expected result. And for the value, I use the current response body. As a set, we'll take it for the expected result. This is the first step. Now we need to go to the test step. The second step is to add this line of code. In simple words, it allows us to work with response body values. It provides a lot of power. And we will learn in deep later in the course how to use it. Also, you need to know is that from now, each time when we will receive a response, the response body will be saved in this JSON object, which renamed the response. And the third step is to compare what we wrote in the pre-request script with what we received in the response. Again, don't be scared. It is simpler than it looks. We have the test name. And then we check the response is the same as the expected result. Let's send the request. And we can see that two tests are run and both are green. As you see, writing the script is not easy. But then you do a lot of work with one click. I want to remind you how we tested this manually. We compared responses and expected results in the node++ with a lot of copy-baseding. And now we can do it with one click. Send the request and see the results. And I want to highlight this one more time for the newcomers. It might look like complex stuff. And it is a complex stuff. But this course is oriented towards the manual QAs who are totally new to API testing and to automation. So you are in the right place. In this video, I just show you the magic which you will be able to do once you finish the course. Let's continue. Before we move to the next test case, we need to fail the current test first. And we can do it in a very easy manner. As you see, we hard code the data here. We expect this response will be exactly like this. The ID1, the name DOM, and etc. So all we need to do to change anything in the body and the test case will fail. The best way is to change something which will change the response body structure. In our case, I deleted the tag. So in the response, there is an empty array. And you can see that test is failed. The reason is that we expected a tag object, ID1, name tag1, instead of receiving an empty array. And the test case failed. We can see one slash two. It is because we have two test cases. And if it will click on the test results tab. We can see which one failed. And we can start to investigate the reason why it failed. But we know the reason. Let's fix it. So both test cases are passed again. And just like this, we automated two test cases out of three. Let's move to the last test case. The response body data is valid. What I mean by that is the data we received in the response should be the same as the data we sent in the request. If we sent ID1, the ID1 should be returned in the response. And the same is related to all the properties. How can we check it? In 99% of cases, you need to compare it to property. You will need to create a separate test for each value. Request ID equals response ID. Request name equals response name. Request status equals response status, etc. That is the proper way to do things. But what we'll do in an lazy way. As you see the request body and the response body are exactly the same. And we are going to use this. We are already halfway through. We can reuse the script which we wrote in the previous test. The response body already has the property. The JSON response object. Now we need the same for the request body. So we add the script. What it does is it saves the request body into the request body JSON object. And then we compare the request data to the response data. As I said, we will talk about it later in the next videos. So I don't explain it too well here. Let's send the request now. When we send the request, we can see that all three test cases are passed. And the last step is to fail the test case with invalid data. Let's send the ID to, for example. And we see that two test cases are passed and one test case is failed. Now the second test case failed and the one which we needed to fail worked fine. So why is that? While we are thinking, let's do a small break. Send up and look around. Care about your body. It is not healthy to sit for hours and hours, drink some coffee or water, and then go back to the API world. We can see what exactly happened. We hard coded data. A second test case expected the ID value to be one. So whenever we send a different ID, the test case is failed. As I said, the way we wrote the second test case is not the best practice, but it is fine for now. We still need to break the third test case, which is passed now. And we will do it in exactly the same manner as we did manually. We will send ID zero. As you see, when we send zero, we receive not or zero in a response, and the two test cases are failed now. And we can see on the test screen the reasons. So we are done. We automated three simple post test cases. What's next? I want to discuss some topics. First of all, you can think. Why do we need to automate this if it didn't take much time manually? Yes, automatic the test case for the first time is time consuming. But once you manage to do it, you can reuse the script. For example, if it will need to test the put endpoint, we will just copy-based all our scripts, do small fixes, and that's all. More important. Yes, for one API and three test cases, it can look like this. But what if you need to run regression testing once a week? And you have not three, but 100 endpoints. And each endpoint has from three to 10 tests. This approach will help you a lot. Each time you need to click on button, so you will need to click send 100 times that is all your job. You don't need to use notepads, tools, compare data, and everything. Now of course we want to click send 100 times. Let me introduce you to the game changer. This little guy, the runner feature. This little guy is the game changer for the regression and other types of testing. Let's click on it. As usual, new complex screen. But we will talk about it in the separate video. What is important for now is that I added three more endpoints. Get put delete endpoints. And the same three tests in each of them. We need to drag and drop our collection to the runner. And when all endpoints will be there, we can start our run. Just click this button. And in one second we have the results. Old 12 test cases are passed. As you see four endpoints, post, get, put, and delete. And the same three test cases for each of them. Isn't that cool? As I said, the game changer. And manually, it would take 15 minutes. And with automation, it can take a couple of seconds. As you can run those every day, so it saves a lot of time. That is why automation is important even for manual QAs. And I want to highlight it one more time. I'm not the automation QA. I'm the manual QA. I haven't worked as an automation tester in any project. That is why these tutorials can have some issues for experience automation engineers. And they are not for them. These tutorials are for manual QAs who want to test the API sufficiently. If you are the manual QA, if you have no experience in API testing at all, if you have no experience in desktop automation, welcome to this journey. And welcome anywhere.